# analytics-repo

This is a Github repository template for analytics use cases. It uses data from [Project CCHAIN](https://thinkingmachines.github.io/project-cchain/), [NASA FIRMS](https://firms.modaps.eosdis.nasa.gov/), and [WAQI](https://waqi.info/). It also uses data engineering configurations from Kenneth Domingo's [analytics-data-eng-play repository](https://github.com/kvdomingo/analytics-data-engg-play/tree/main).

## Sample Use Cases <br>

1) Linking precipitation and dengue cases in selected Philippine cities. Project CCHAIN datasets are in GCS(.csv). <br>

2) Linking air quality index and fires in Chiang Mai. Air quality indices come from WAQI (stored in GCS), while hotspot/fire data comes from NASA FIRMS (accessible via API).

## Tech stack <br>
- [Python 3.12](https://docs.python.org/3.12/)
- [uv](https://docs.astral.sh/uv)
- [Dagster](https://docs.dagster.io)
- [Polars](https://docs.pola.rs)
- [DuckDB](https://duckdb.org/docs/stable/)

## Prerequisites <br>
- [Mise](https://mise.jdx.dev/getting-started.html)
- [Docker](https://docker.com)

## Workflow <br>

(*insert schematic diagram here*)

### Setting up the environment<br>

| File/Configuration | Description |
| **dagster.yaml** | dagster instance configuration |
| **docker-compose.yaml** | sets up dagster with PostgreSQL backend |
| **Dockerfile** | create docker image |
| **.env.example** | template for keys and credentials |
| **.gitattributes** | behaviors for specific file types (i.e., json be read using Python syntax) |
| **.gitignore** | defines files to exclude from Git tracking |
| **.mise.toml** | development environment and dependencies. |
| **.pre-commit-config.yaml** | automates linting, formatting, and validation |
| **pyproject.toml**| dependencies, build system, and tool configuration |
| **taskfile.yaml** | creates tasks that can be written out in the terminal |

*Note: All other files are autogenerated.*

### Other folders

| Folder | Description |
| **data** | stores datasets and databases |
| **docs** | additional documentation for env setup |
| **notebooks** | jupyter notebooks for data processing and visualization |
| **tests** | test scripts to validate the workflow |

#### Source code (src)

**src** contains Python scripts for reusable components (e.g., functions, imports, paths) used in the pipeline. It is categorized into the following files and folders. Note that `__init__.py` files are needed so that directories can work properly as Python packages.

| File/ Folder         | Description  |
|-------------------|-----------------------------------------------|
|**assets**| creating dagster assets (and jobs) |
| **core.py** | functions for extracting from GCS and creating metadata |
| **definitions.py** | how everything (tools) works together |
| **partitions.py** | division of data into time segments |
| **resources.py** | sets up tools and connections |
| **settings.py** | configuration and environment variables |

## Instructions for use <br>

1. Make sure that Docker is integrated to your OS. In Docker Desktop: Settings > Resources > WSL Integration > Select applicable. To check if Docker is running, run `docker --version`.
    ```shell
    docker --version
    ```
<br>

2. Install requirements in shell. **No need to run if these are already present in your system.** Note that repeating installs for `curl` will install multiple versions in your local.
    ```shell
    curl https://mise.run | sh #mise
    sudo snap install task #task
    ```
<br>

3. Make sure `mise` is activated and running properly by running `mise doctor`. If `mise` is not activated, run `eval "$(mise activate bash)"`.
    ```shell
    mise doctor
    eval "$(mise activate bash)"
    ```
<br>


4. Install tools in shell. See [.mise.toml](./.mise.toml) for a list of tools. `mise trust -y` checks for untrusted configuration tools. A `mise WARN` message stating "No untrusted config files found" means that config files are already trusted and no updates are needed.
    ```shell
    mise trust -y
    mise install -y
    ```
<br>

5. Run initial [setup script](./Taskfile.yml#L8) (i.e., `init` in `taskfile.yaml`). This will install [pre-commit hooks](./.pre-commit-config.yaml) for the project. It automates creation of the following files/folders: (a) `.python-version`, (b) `main.py`, (c) `uv.lock`, and (d) `/data/lake`.
    ```shell
    task init
    ```
    Note that you may need to run `uv init` if you are running a blank project. The task only syncs `uv` with the existing `pyproject.toml`.
<br>

6. Create a `.env` file using the template `.env.example`. <br>

7. Login to GCloud.
    ```shell
    gcloud auth login --update-adc
    ```
<br>

8. Build and start the [Docker container](./Taskfile.yml#L16=8) (i.e., `up` in `taskfile.yaml`). This will also setup cache folders for initialization and log files, linters, the virtual environment, and build artifacts.
    ```shell
    task up
    ```
<br>

9. Access the Dagster UI at `http://localhost:3030`. Both Dagster and Dagster-DB should be running and healthy. It takes a while to setup, but you can watch logs using the command below.
    ```shell
    task logs
    ```
<br>

10. To stop the running container, press `Ctrl+C` and stop the container.
    ```shell
    task down
    ```
<br>
