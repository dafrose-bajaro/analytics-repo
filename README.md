# analytics-repo

This is a Github repository template for analytics use cases. It uses data from [Project CCHAIN](https://thinkingmachines.github.io/project-cchain/) and uses some of the configurations from Kenneth Domingo's [analytics-data=eng-play respository](https://github.com/kvdomingo/analytics-data-engg-play/tree/main).

## Sample Use Case <br><br>

Linking precipitation and dengue cases in selected Philippine cities to find trends and insights. <br><br>

## Tech stack <br><br>
- [Python 3.12](https://docs.python.org/3.12/)
- [uv](https://docs.astral.sh/uv)
- [Dagster](https://docs.dagster.io)
- [Polars](https://docs.pola.rs)
- [DuckDB](https://duckdb.org/docs/stable/)
- [dbt](https://docs.getdbt.com/)

## Prerequisites <br><br>
- [Mise](https://mise.jdx.dev/getting-started.html)
- [Docker](https://docker.com)

## Key files<br><br>

- **dagster.yaml** configures a Dagster instance by defining settings for storage, run execution, logging, sensors, and schedulers. <br><br>

- **dbt_project.yaml** configures a dbt project by defining settings like project name, version, pths, models, and other configurations. <br><br>

- **docker-compose.yaml** defines Dagster as the main service for managing data workflows, PostgreSQL for storage, and configures environment variables. <br><br>

- **Dockerfile** creates a Docker image to prepare the environment, install dependencies, and set configurations for the workflow to function. <br><br>

- **.env.example** contains a template for keys and credentials. Create an actual **.env** file containing actual keys and credentials. It is worth noting that .env files should be included in gitignore so it does not get uploaded to the remote repository. <br><br>

- **.gitattributes** defines attributes and behaviors for specific file types and paths. For this specific repository, we ask that Jupyter notebooks (.json) be read using Python syntax. <br><br>
- **.gitignore** defines files to exclude from Git tracking. It uses a Python template and ignores Windows files and the data folder. <br><br>

- **.mise.toml** manages development environment and dependencies. <br><br>

- **.pre-commit-config.yaml** automates linting, formatting, and validation. It includes the following repos: (a) ruff-pre-commit, (b) sqlfluff, (c) jupytext, and (d) pre-commit hooks. <br><br>

- **profiles.yaml** defines how dbt connects to the database. The database type is DuckDB and it allocates 16 thread for parallel processing. <br><br>

- **README.md** provides an overview of the repository: its purpose, structure, and instructions for setup. <br><br>

- **taskfile.yaml** automates tasks for container management and project workflows. Each task corresponds to a specific command that can be excuted. <br><br>

*Note*: All other files are autogenerated. <br><br>

## Key folders <br><br>

- **data** stores the datasets. Git tracking ignores this folder as this mainly includes large downloaded files. It is structured into raw and processed data. <br><br>

- **docs** contains additional files documenting details for specific files, folders, functions, and processes. <br><br>

- **notebooks** contains Jupyter notebooks that can be run for downloading data, doing EDAs, and visualization. Categories under this folder include: (a) download, (b) processing, (c) analysis, and (d) visualization. <br><br>

- **src** contains Python scripts for reusable components (e.g., functions, imports, paths) used in the pipeline. <br><br>

- **tests** contains test scripts to validate the workflow. <br><br>

## Instructions for use <br><br>

1. Make sure that Docker is integrated to your OS. In Docker Desktop: Settings > Resources > WSL Integration > Select applicable. To check if Docker is running, run `docker --version`.
    ```shell
    docker --version
    ```
<br>

2. Install requirements in shell. No need to run if these are already present in your system. Note that repeating installs for `curl` will install multiple versions in your local.
    ```shell
    curl https://mise.run | sh #mise
    sudo snap install task #task
    ```
<br>

3. Make sure `mise` is activated by running `mise doctor`. If `mise` is not activated, run `eval "$(mise activate bash)"`.
    ```shell
    mise doctor
    eval "$(mise activate bash)"
    ```
<br>


4. Install tools in shell. See [.mise.toml](./.mise.toml). `mise trust -y` checks for untrusted configuration tools. A `mise WARN` message stating "No untrusted config files found" means that config files are already trusted and no updates are needed.
    ```shell
    mise trust -y
    mise install -y
    ```
<br>

5. Run initial [setup script](./Taskfile.yml#L8)(i.e., `init` in `taskfile.yaml`). This will install [pre-commit hooks](./.pre-commit-config.yaml) and create the [Python virtualenv](./pyproject.toml) for the project. It automates creation of the following files/folders: (a) `pyproject.toml`, (b) `.python-version`, (c) `main.py`, (d) `uv.lock`, and (e) `/data/lake`.
    ```shell
    task init
    ```
<br>

6. Create a `.env` file using the template `.env.example`. You need to provide your secrets.
<br>

7. Build and start the [Docker container](./Taskfile.yml#L16=8) (i.e., `up` in `taskfile.yaml`).
    ```shell
    task up
    ```
<br>

8. Access the Dagster UI at `http://localhost:3030`. Both Dagster and Dagster-DB should be healthy.
<br>
