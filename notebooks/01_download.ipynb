{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download\n",
    "\n",
    "This notebook downloads the data from Project CCHAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All CSV files from a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: disease_pidsr_totals.csv\n",
      "Downloaded: disease_fhsis_totals.csv\n",
      "Downloaded: disease_psa_totals.csv\n",
      "Downloaded: disease_lgu_disaggregated_totals.csv\n",
      "Downloaded: climate_atmosphere.csv\n",
      "Downloaded: climate_atmosphere_downscaled.csv\n",
      "Downloaded: climate_air_quality.csv\n",
      "Downloaded: climate_indices.csv\n",
      "Downloaded: climate_land.csv\n",
      "Downloaded: climate_timestep_check.csv\n",
      "Downloaded: geoportal_doh_poi_health.csv\n",
      "Downloaded: osm_poi_amenity.csv\n",
      "Downloaded: osm_poi_health.csv\n",
      "Downloaded: osm_poi_sanitation.csv\n",
      "Downloaded: osm_poi_water_body.csv\n",
      "Downloaded: osm_poi_total.csv\n",
      "Downloaded: esa_worldcover.csv\n",
      "Downloaded: project_noah_hazards.csv\n",
      "Downloaded: google_open_buildings.csv\n",
      "Downloaded: mapbox_health_facility_brgy_isochrones.csv\n",
      "Downloaded: mapbox_health_facility_city_isochrones.csv\n",
      "Downloaded: worldpop_population.csv\n",
      "Downloaded: ookla_internet_speed.csv\n",
      "Downloaded: nighttime_lights.csv\n",
      "Downloaded: tm_relative_wealth_index.csv\n",
      "Downloaded: tm_open_buildings.csv\n",
      "Downloaded: calendar.csv\n",
      "Downloaded: disease.csv\n",
      "Downloaded: location.csv\n",
      "Downloaded: brgy_geography.csv\n",
      "All CSV files downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# source url\n",
    "url = \"https://data.humdata.org/dataset/project-cchain\"\n",
    "\n",
    "# output folder\n",
    "download_folder = \"../data/01_raw\"\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# function\n",
    "def download_csv_files(url, download_folder):\n",
    "    try:\n",
    "\n",
    "        # get url content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # parse html\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        # find links with .csv extension\n",
    "        csv_links = soup.find_all(\"a\", href=True)\n",
    "        csv_files = [link[\"href\"] for link in csv_links if link[\"href\"].endswith(\".csv\")]\n",
    "\n",
    "        # download csv\n",
    "        for relative_url in csv_files:\n",
    "            csv_url = urljoin(url, relative_url)\n",
    "            file_name = os.path.basename(csv_url)\n",
    "            file_path = os.path.join(download_folder, file_name)\n",
    "            \n",
    "            csv_response = requests.get(csv_url)\n",
    "            csv_response.raise_for_status()  # Ensure the request was successful\n",
    "            with open(file_path, \"wb\") as file:\n",
    "                file.write(csv_response.content)\n",
    "            \n",
    "            print(f\"Downloaded: {file_name}\")\n",
    "\n",
    "        print(\"All CSV files downloaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "# apply\n",
    "download_csv_files(url, download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected files only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://data.humdata.org/dataset/5b580664-365e-4d7e-b5e5-2990df8f12a5/resource/eb1341ec-296f-442c-a741-6e78fca31332/download/osm_poi_sanitation.csv\n",
      "Downloaded: osm_poi_sanitation.csv\n",
      "All files downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# list of urls\n",
    "url_list = [\n",
    "    \"https://data.humdata.org/dataset/5b580664-365e-4d7e-b5e5-2990df8f12a5/resource/eb1341ec-296f-442c-a741-6e78fca31332/download/osm_poi_sanitation.csv\",\n",
    "    # add more urls here\n",
    "]\n",
    "\n",
    "# output folder\n",
    "download_folder = \"../data/01_raw\"\n",
    "os.makedirs(download_folder, exist_ok=True)\n",
    "\n",
    "# function\n",
    "def download_files(url_list, download_folder):\n",
    "    try:\n",
    "        \n",
    "        # loop through urls and downlaod\n",
    "        for url in url_list:\n",
    "            file_name = os.path.basename(url)\n",
    "            file_path = os.path.join(download_folder, file_name)\n",
    "            \n",
    "            print(f\"Downloading: {url}\")\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  \n",
    "            \n",
    "            with open(file_path, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "            print(f\"Downloaded: {file_name}\")\n",
    "        \n",
    "        print(\"All files downloaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "# apply\n",
    "download_files(url_list, download_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then add these files to Google Cloud Storage. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
